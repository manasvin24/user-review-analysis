{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e698359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# installs dependencies and imports required libraries.\n",
    "%pip install -q pandas torch nltk sentence-transformers transformers tqdm\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import torch\n",
    "from nltk.corpus import words\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c91629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the input data location.\n",
    "DATA_PATH = Path('../data/BDFoodSent-334k.csv')  # Adjust this path as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfb6597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at deepset/bert-base-cased-squad2 were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: b2e4521f-a55c-4196-bdee-e0814cf0e350)')' thrown while requesting HEAD https://huggingface.co/deepset/bert-base-cased-squad2/resolve/main/processor_config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "'(ProtocolError('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')), '(Request ID: b2e4521f-a55c-4196-bdee-e0814cf0e350)')' thrown while requesting HEAD https://huggingface.co/deepset/bert-base-cased-squad2/resolve/main/processor_config.json\n",
      "Retrying in 1s [Retry 1/5].\n",
      "Device set to use mps:0\n",
      "Device set to use mps:0\n"
     ]
    }
   ],
   "source": [
    "# preparing aspect questions and initializing the qa pipeline.\n",
    "aspect_questions = {\n",
    "    'Taste_Aspect': 'What is the opinion about the taste, quantity or food quality?',\n",
    "    'Service_Aspect': 'What is the feedback on the service or delivery?',\n",
    "    \"Ambiance_Aspect\": \"What is the description of the restaurant's atmosphere or environment?\"\n",
    "}\n",
    "\n",
    "df_reviews = pd.read_csv(DATA_PATH)\n",
    "qa_pipeline = pipeline('question-answering', model='deepset/bert-base-cased-squad2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f3eade",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "QA extraction: 100%|██████████| 100/100 [00:04<00:00, 21.89it/s]\n",
      "QA extraction: 100%|██████████| 100/100 [00:04<00:00, 21.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# running qa extraction for each review and aspect.\n",
    "results = []\n",
    "\n",
    "for _, row in tqdm(df_reviews.iterrows(), total=len(df_reviews), desc='QA extraction'):\n",
    "    review_text = row['text']\n",
    "    restaurant_id = row['name']\n",
    "    city = row['city']\n",
    "\n",
    "    for aspect, question_text in aspect_questions.items():\n",
    "        try:\n",
    "            output = qa_pipeline(question=question_text, context=review_text)\n",
    "            answer = output.get('answer', '')\n",
    "            score = output.get('score', 0.0)\n",
    "        except Exception:\n",
    "            answer = ''\n",
    "            score = 0.0\n",
    "\n",
    "        results.append({\n",
    "            'review': review_text,\n",
    "            'restaurant_id': restaurant_id,\n",
    "            'city': city,\n",
    "            'question': aspect,\n",
    "            'answer': answer,\n",
    "            'confidence': score\n",
    "        })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c6381e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>restaurant_id</th>\n",
       "      <th>city</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>too much small amount</td>\n",
       "      <td>Restaurant 2914</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>Taste_Aspect</td>\n",
       "      <td>too much small amount</td>\n",
       "      <td>0.136931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>too much small amount</td>\n",
       "      <td>Restaurant 2914</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>Service_Aspect</td>\n",
       "      <td>too much small amount</td>\n",
       "      <td>0.082128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>too much small amount</td>\n",
       "      <td>Restaurant 2914</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>Ambiance_Aspect</td>\n",
       "      <td>too much small amount</td>\n",
       "      <td>0.071102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>very small in amount</td>\n",
       "      <td>Restaurant 2914</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>Taste_Aspect</td>\n",
       "      <td>very small</td>\n",
       "      <td>0.365033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>very small in amount</td>\n",
       "      <td>Restaurant 2914</td>\n",
       "      <td>Dhaka</td>\n",
       "      <td>Service_Aspect</td>\n",
       "      <td>very small in amount</td>\n",
       "      <td>0.000749</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  review    restaurant_id   city         question  \\\n",
       "0  too much small amount  Restaurant 2914  Dhaka     Taste_Aspect   \n",
       "1  too much small amount  Restaurant 2914  Dhaka   Service_Aspect   \n",
       "2  too much small amount  Restaurant 2914  Dhaka  Ambiance_Aspect   \n",
       "3   very small in amount  Restaurant 2914  Dhaka     Taste_Aspect   \n",
       "4   very small in amount  Restaurant 2914  Dhaka   Service_Aspect   \n",
       "\n",
       "                  answer  confidence  \n",
       "0  too much small amount    0.136931  \n",
       "1  too much small amount    0.082128  \n",
       "2  too much small amount    0.071102  \n",
       "3             very small    0.365033  \n",
       "4   very small in amount    0.000749  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# previewing the qa extraction results.\n",
    "df_results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1869db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [00:11<00:00, 26.93it/s]\n",
      "100%|██████████| 300/300 [00:11<00:00, 26.93it/s]\n"
     ]
    }
   ],
   "source": [
    "# computing cosine similarity between questions and answers.\n",
    "tqdm.pandas()\n",
    "sentence_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "def calculate_similarity(row):\n",
    "    \"\"\"Calculate cosine similarity between question and answer embeddings.\n",
    "    \n",
    "    Args:\n",
    "        row (pd.Series): A row from the DataFrame containing 'question' and 'answer' columns.\n",
    "\n",
    "    Returns:\n",
    "        float: Cosine similarity score between question and answer embeddings.\n",
    "    \"\"\"\n",
    "    question = row['question']\n",
    "    answer = row['answer']\n",
    "\n",
    "    if not isinstance(answer, str) or not answer.strip():\n",
    "        return 0.0\n",
    "\n",
    "    q_emb = sentence_model.encode(question, convert_to_tensor=True)\n",
    "    a_emb = sentence_model.encode(answer, convert_to_tensor=True)\n",
    "\n",
    "    if q_emb.dim() == 1:\n",
    "        q_emb = q_emb.unsqueeze(0)\n",
    "    if a_emb.dim() == 1:\n",
    "        a_emb = a_emb.unsqueeze(0)\n",
    "\n",
    "    return util.cos_sim(q_emb, a_emb).item()\n",
    "\n",
    "df_results['cosine_sim'] = df_results.progress_apply(calculate_similarity, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e1c4bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     /Users/manasvinsurya/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/words.zip.\n"
     ]
    }
   ],
   "source": [
    "# downloading vocabulary resources and defining filtering helpers.\n",
    "nltk.download('words')\n",
    "ENGLISH_WORDS = set(words.words())\n",
    "WORD_RE = re.compile(r'[A-Za-z]+')\n",
    "\n",
    "def filter_short_sentences(df, column, min_words=5):\n",
    "    \"\"\"Filter out sentences with fewer than a specified number of words.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the text data.\n",
    "        column (str): Name of the column containing text to filter.\n",
    "        min_words (int, optional): Minimum number of words required to keep a sentence. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered DataFrame with sentences meeting the word count criteria.\n",
    "    \"\"\"\n",
    "    mask = df[column].apply(lambda text: len(str(text).split()) >= min_words)\n",
    "    return df[mask].reset_index(drop=True)\n",
    "\n",
    "def filter_english_heavy(df, column, threshold=0.5):\n",
    "    \"\"\"Filter out sentences with a low ratio of English words.\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the text data.\n",
    "        column (str): Name of the column containing text to filter.\n",
    "        threshold (float, optional): Minimum ratio of English words required to keep a sentence. Defaults to 0.5.\n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered DataFrame with sentences meeting the English word ratio criteria.\n",
    "    \"\"\"\n",
    "    def english_ratio(text):\n",
    "        \"\"\"Calculate the ratio of English words in the given text.\n",
    "        Args:\n",
    "            text (str): The text to analyze.\n",
    "        Returns:\n",
    "            float: Ratio of English words to total words in the text.\"\"\"\n",
    "        tokens = WORD_RE.findall(str(text).lower())\n",
    "        if not tokens:\n",
    "            return 0\n",
    "        eng_count = sum(1 for token in tokens if token in ENGLISH_WORDS)\n",
    "        return eng_count / len(tokens)\n",
    "\n",
    "    mask = df[column].apply(lambda text: english_ratio(text) >= threshold)\n",
    "    return df[mask].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4e7e3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>cosine_sim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>255.000000</td>\n",
       "      <td>255.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.172880</td>\n",
       "      <td>0.083248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.192067</td>\n",
       "      <td>0.150791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.182185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.032478</td>\n",
       "      <td>-0.037973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.100414</td>\n",
       "      <td>0.070207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.242805</td>\n",
       "      <td>0.186579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.907947</td>\n",
       "      <td>0.645607</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       confidence  cosine_sim\n",
       "count  255.000000  255.000000\n",
       "mean     0.172880    0.083248\n",
       "std      0.192067    0.150791\n",
       "min      0.000004   -0.182185\n",
       "25%      0.032478   -0.037973\n",
       "50%      0.100414    0.070207\n",
       "75%      0.242805    0.186579\n",
       "max      0.907947    0.645607"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# applying text filters to refine the qa results.\n",
    "filtered_df = filter_short_sentences(df_results, 'review', min_words=3)\n",
    "filtered_df = filter_english_heavy(filtered_df, 'review', threshold=0.5)\n",
    "filtered_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9b3b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Food (Taste): Full Shape (85, 7), Top 10% Shape (8, 7)\n",
      "Ambiance: Full Shape (85, 7), Top 10% Shape (8, 7)\n",
      "Service: Full Shape (85, 7), Top 10% Shape (8, 7)\n"
     ]
    }
   ],
   "source": [
    "# selecting top reviews per aspect using cosine similarity.\n",
    "def filter_top_aspect(df, aspect_label):\n",
    "    \"\"\"Filter reviews by aspect and select the top 10% based on cosine similarity.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the review data.\n",
    "        aspect_label (str): The aspect label to filter by.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the full subset and the top 10% subset based on cosine similarity.\n",
    "    \"\"\"\n",
    "    subset = df[df['question'] == aspect_label].copy()\n",
    "    subset = subset.sort_values(by='cosine_sim', ascending=False)\n",
    "    top_n = int(len(subset) * 0.1)\n",
    "    top_subset = subset.head(top_n) if top_n > 0 else subset\n",
    "    return subset, top_subset\n",
    "\n",
    "food_full, df_food = filter_top_aspect(filtered_df, 'Taste_Aspect')\n",
    "ambiance_full, df_ambiance = filter_top_aspect(filtered_df, 'Ambiance_Aspect')\n",
    "service_full, df_service = filter_top_aspect(filtered_df, 'Service_Aspect')\n",
    "\n",
    "print(f\"Food (Taste): Full Shape {food_full.shape}, Top 10% Shape {df_food.shape}\")\n",
    "print(f\"Ambiance: Full Shape {ambiance_full.shape}, Top 10% Shape {df_ambiance.shape}\")\n",
    "print(f\"Service: Full Shape {service_full.shape}, Top 10% Shape {df_service.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9da23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Food Reviews...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 15.01it/s]\n",
      "/var/folders/94/m2ybvb713y1gwdk84ny9yp080000gn/T/ipykernel_5025/505564511.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_food['sentiment'] = df_food['review'].progress_apply(get_sentiment_score)\n",
      "100%|██████████| 8/8 [00:00<00:00, 15.01it/s]\n",
      "/var/folders/94/m2ybvb713y1gwdk84ny9yp080000gn/T/ipykernel_5025/505564511.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_food['sentiment'] = df_food['review'].progress_apply(get_sentiment_score)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Ambiance Reviews...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 27.41it/s]\n",
      "/var/folders/94/m2ybvb713y1gwdk84ny9yp080000gn/T/ipykernel_5025/505564511.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ambiance['sentiment'] = df_ambiance['review'].progress_apply(get_sentiment_score)\n",
      "100%|██████████| 8/8 [00:00<00:00, 27.41it/s]\n",
      "/var/folders/94/m2ybvb713y1gwdk84ny9yp080000gn/T/ipykernel_5025/505564511.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_ambiance['sentiment'] = df_ambiance['review'].progress_apply(get_sentiment_score)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Service Reviews...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 30.85it/s]\n",
      "/var/folders/94/m2ybvb713y1gwdk84ny9yp080000gn/T/ipykernel_5025/505564511.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_service['sentiment'] = df_service['review'].progress_apply(get_sentiment_score)\n",
      "100%|██████████| 8/8 [00:00<00:00, 30.85it/s]\n",
      "/var/folders/94/m2ybvb713y1gwdk84ny9yp080000gn/T/ipykernel_5025/505564511.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_service['sentiment'] = df_service['review'].progress_apply(get_sentiment_score)\n"
     ]
    }
   ],
   "source": [
    "# performing sentiment scoring on the aspect-specific reviews.\n",
    "sentiment_pipe = pipeline(\n",
    "    'sentiment-analysis',\n",
    "    model='nlptown/bert-base-multilingual-uncased-sentiment',\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "def get_sentiment_score(review):\n",
    "    \"\"\"Get sentiment score for a given review text.\n",
    "    Args:\n",
    "        review (str): The review text to analyze.\n",
    "    Returns:\n",
    "        float: Sentiment score of the review.\n",
    "    \"\"\"\n",
    "    if not isinstance(review, str):\n",
    "        review = str(review)\n",
    "    return sentiment_pipe(review)[0]['score']\n",
    "\n",
    "print('Processing Food Reviews...')\n",
    "df_food['sentiment'] = df_food['review'].progress_apply(get_sentiment_score)\n",
    "\n",
    "print('Processing Ambiance Reviews...')\n",
    "df_ambiance['sentiment'] = df_ambiance['review'].progress_apply(get_sentiment_score)\n",
    "\n",
    "print('Processing Service Reviews...')\n",
    "df_service['sentiment'] = df_service['review'].progress_apply(get_sentiment_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb120545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results_food_sentiment.csv, results_ambiance_sentiment.csv, results_service_sentiment.csv\n"
     ]
    }
   ],
   "source": [
    "# writing sentiment outputs to the results directory.\n",
    "results_dir = Path('../results')\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "df_food.to_csv(results_dir / 'Food_sentiment_bert_base_cased.csv', index=False)\n",
    "df_ambiance.to_csv(results_dir / 'Ambiance_sentiment_bert_base_cased.csv', index=False)\n",
    "df_service.to_csv(results_dir / 'Service_sentiment_bert_base_cased.csv', index=False)\n",
    "\n",
    "print('Saved Food_sentiment_bert_base_cased.csv, Ambiance_sentiment_bert_base_cased.csv, Service_sentiment_bert_base_cased.csv to results/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8467710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing no operation in this cell.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
