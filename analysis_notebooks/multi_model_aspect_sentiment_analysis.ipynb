{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "861c524c",
   "metadata": {},
   "source": [
    "# Restaurant Review Sentiment Analysis\n",
    "## Multi-Aspect, Multi-Model Comparative Analysis\n",
    "\n",
    "This notebook analyzes restaurant reviews across three aspects (Food, Service, Ambiance) using two sentiment analysis models (TinyRoBERTa and DistilBERT).\n",
    "\n",
    "**Dataset Overview:**\n",
    "- 3 Aspects: Food, Service, Ambiance\n",
    "- 2 Models: TinyRoBERTa SQuAD2, DistilBERT Base Uncased\n",
    "- 6 Total Files for comprehensive comparison\n",
    "\n",
    "**Analysis Goals:**\n",
    "1. Compare model performance and agreement\n",
    "2. Identify sentiment patterns across aspects\n",
    "3. Discover geographic and restaurant-level insights\n",
    "4. Understand confidence scores and prediction reliability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f89d3a",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf2a0b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from scipy import stats\n",
    "from scipy.stats import pearsonr, spearmanr, chi2_contingency\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set visualization styles\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "# Configure pandas display\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1db03a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Define file paths\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m results_dir \u001b[38;5;241m=\u001b[39m Path(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../results\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Load all files\u001b[39;00m\n\u001b[1;32m      5\u001b[0m files \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAmbiance_BERT\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAmbiance_sentiment_bert_base_cased.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAmbiance_TinyRoBERTa\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAmbiance_sentiment_tinyroberta_squad2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mService_TinyRoBERTa\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mService_sentiment_tinyroberta_squad2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     12\u001b[0m }\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "# Define aspect sentiment file paths\n",
    "results_dir = Path('../results')\n",
    "\n",
    "# Load all files\n",
    "files = {\n",
    "    'Ambiance_BERT': 'ambiance_sentiment_bert_base_cased.csv',\n",
    "    'Ambiance_TinyRoBERTa': 'ambiance_sentiment_tinyroberta_squad2.csv',\n",
    "    'Food_BERT': 'food_sentiment_bert_base_cased.csv',\n",
    "    'Food_TinyRoBERTa': 'food_sentiment_tinyroberta_squad2.csv',\n",
    "    'Service_BERT': 'service_sentiment_bert_base_cased.csv',\n",
    "    'Service_TinyRoBERTa': 'service_sentiment_tinyroberta_squad2.csv'\n",
    "}\n",
    "\n",
    "data = {}\n",
    "for key, filename in files.items():\n",
    "    filepath = results_dir / filename\n",
    "    data[key] = pd.read_csv(filepath)\n",
    "    print(f\"✅ {key}: {len(data[key])} rows\")\n",
    "\n",
    "print(f\"\\nTotal datasets loaded: {len(data)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6730f2f7",
   "metadata": {},
   "source": [
    "## 2. Data Overview and Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cbe698",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display first few rows\n",
    "print(\"Sample of consolidated data:\")\n",
    "df_all.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd485a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data shape and info\n",
    "print(\"=\" * 80)\n",
    "print(\"DATA STRUCTURE SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nTotal Records: {df_all.shape[0]:,}\")\n",
    "print(f\"Total Columns: {df_all.shape[1]}\")\n",
    "print(f\"\\nColumn Names:\")\n",
    "print(df_all.columns.tolist())\n",
    "print(f\"\\nData Types:\")\n",
    "print(df_all.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7dd1d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Column': df_all.columns,\n",
    "    'Missing_Count': df_all.isnull().sum(),\n",
    "    'Missing_Percentage': (df_all.isnull().sum() / len(df_all) * 100).round(2)\n",
    "})\n",
    "missing_summary = missing_summary[missing_summary['Missing_Count'] > 0].sort_values('Missing_Count', ascending=False)\n",
    "\n",
    "if len(missing_summary) > 0:\n",
    "    print(missing_summary.to_string(index=False))\n",
    "else:\n",
    "    print(\"✓ No missing values found in the dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8689619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics by aspect and model\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RECORD COUNT BY ASPECT AND MODEL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "summary_table = df_all.groupby(['Aspect', 'Model']).size().reset_index(name='Record_Count')\n",
    "summary_pivot = summary_table.pivot(index='Aspect', columns='Model', values='Record_Count')\n",
    "print(summary_pivot)\n",
    "\n",
    "# Total by aspect\n",
    "print(\"\\nTotal by Aspect:\")\n",
    "print(df_all.groupby('Aspect').size().sort_values(ascending=False))\n",
    "\n",
    "# Total by model\n",
    "print(\"\\nTotal by Model:\")\n",
    "print(df_all.groupby('Model').size().sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c878ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics for numerical columns\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"NUMERICAL COLUMNS STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "numerical_cols = df_all.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print(f\"\\nNumerical columns: {numerical_cols}\")\n",
    "print(\"\\nDescriptive Statistics:\")\n",
    "df_all[numerical_cols].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b861fabf",
   "metadata": {},
   "source": [
    "## 3. Sentiment Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082e51bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall sentiment distribution\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('Sentiment Label Distribution by Aspect and Model', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, (key, df) in enumerate(dataframes.items()):\n",
    "    row = idx // 3\n",
    "    col = idx % 3\n",
    "    ax = axes[row, col]\n",
    "    \n",
    "    sentiment_counts = df['Sentiment_Label'].value_counts().sort_index()\n",
    "    colors = ['#d62728', '#ff7f0e', '#bcbd22', '#2ca02c', '#17becf']\n",
    "    \n",
    "    sentiment_counts.plot(kind='bar', ax=ax, color=colors[:len(sentiment_counts)])\n",
    "    ax.set_title(f\"{df['Aspect'].iloc[0]} - {df['Model'].iloc[0]}\", fontweight='bold')\n",
    "    ax.set_xlabel('Sentiment Label (Stars)')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(sentiment_counts):\n",
    "        ax.text(i, v + 5, str(v), ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Sentiment distribution visualization complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5770339f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie charts for sentiment distribution\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=3,\n",
    "    subplot_titles=[f\"{df['Aspect'].iloc[0]} - {df['Model'].iloc[0]}\" for df in dataframes.values()],\n",
    "    specs=[[{'type':'pie'}]*3, [{'type':'pie'}]*3]\n",
    ")\n",
    "\n",
    "colors = ['#d62728', '#ff7f0e', '#bcbd22', '#2ca02c', '#17becf']\n",
    "\n",
    "for idx, (key, df) in enumerate(dataframes.items()):\n",
    "    row = idx // 3 + 1\n",
    "    col = idx % 3 + 1\n",
    "    \n",
    "    sentiment_counts = df['Sentiment_Label'].value_counts().sort_index()\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Pie(labels=[f\"{int(x)} Star\" for x in sentiment_counts.index],\n",
    "               values=sentiment_counts.values,\n",
    "               marker=dict(colors=colors[:len(sentiment_counts)]),\n",
    "               textinfo='label+percent',\n",
    "               hovertemplate='%{label}<br>Count: %{value}<br>Percentage: %{percent}<extra></extra>'),\n",
    "        row=row, col=col\n",
    "    )\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Sentiment Distribution - Pie Charts Overview\",\n",
    "    height=800,\n",
    "    showlegend=False\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a27ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparative sentiment distribution across aspects\n",
    "aspect_comparison = df_all.groupby(['Aspect', 'Sentiment_Label']).size().reset_index(name='Count')\n",
    "aspect_pivot = aspect_comparison.pivot(index='Sentiment_Label', columns='Aspect', values='Count').fillna(0)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "aspect_pivot.plot(kind='bar', ax=ax, width=0.8)\n",
    "ax.set_title('Sentiment Distribution Comparison Across Aspects', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Sentiment Label (Stars)', fontsize=12)\n",
    "ax.set_ylabel('Count', fontsize=12)\n",
    "ax.legend(title='Aspect', title_fontsize=12, fontsize=11)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.xticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nSentiment Count by Aspect:\")\n",
    "print(aspect_pivot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e1f6a7",
   "metadata": {},
   "source": [
    "## 4. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e52bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for model comparison\n",
    "# For each aspect, merge TinyRoBERTa and DistilBERT predictions\n",
    "\n",
    "model_comparisons = {}\n",
    "\n",
    "for aspect in ['food', 'service', 'ambiance']:\n",
    "    df_tiny = dataframes[f'{aspect}_tinyroberta'].copy()\n",
    "    df_distil = dataframes[f'{aspect}_distilbert'].copy()\n",
    "    \n",
    "    # Merge on common columns (assuming Restaurant_id and Review_id exist)\n",
    "    # If they don't exist, we'll merge on index\n",
    "    if 'Review_id' in df_tiny.columns:\n",
    "        merged = df_tiny.merge(df_distil, \n",
    "                               on=['Review_id', 'Restaurant_id'], \n",
    "                               suffixes=('_tiny', '_distil'))\n",
    "    else:\n",
    "        # Merge on index\n",
    "        df_tiny_indexed = df_tiny.reset_index()\n",
    "        df_distil_indexed = df_distil.reset_index()\n",
    "        merged = df_tiny_indexed.merge(df_distil_indexed, \n",
    "                                       left_index=True, right_index=True,\n",
    "                                       suffixes=('_tiny', '_distil'))\n",
    "    \n",
    "    model_comparisons[aspect.capitalize()] = merged\n",
    "    print(f\"{aspect.capitalize()}: {len(merged)} matching records\")\n",
    "\n",
    "print(\"\\n✓ Model comparison datasets prepared!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734cda57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate agreement rates between models\n",
    "print(\"=\" * 80)\n",
    "print(\"MODEL AGREEMENT ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "agreement_results = []\n",
    "\n",
    "for aspect, df_comp in model_comparisons.items():\n",
    "    # Exact match agreement\n",
    "    exact_match = (df_comp['Sentiment_Label_tiny'] == df_comp['Sentiment_Label_distil']).sum()\n",
    "    total = len(df_comp)\n",
    "    agreement_rate = (exact_match / total * 100)\n",
    "    \n",
    "    # Within 1 star agreement\n",
    "    diff = abs(df_comp['Sentiment_Label_tiny'] - df_comp['Sentiment_Label_distil'])\n",
    "    within_1_star = (diff <= 1).sum()\n",
    "    within_1_rate = (within_1_star / total * 100)\n",
    "    \n",
    "    agreement_results.append({\n",
    "        'Aspect': aspect,\n",
    "        'Total_Records': total,\n",
    "        'Exact_Match': exact_match,\n",
    "        'Exact_Agreement_%': round(agreement_rate, 2),\n",
    "        'Within_1_Star': within_1_star,\n",
    "        'Within_1_Star_%': round(within_1_rate, 2)\n",
    "    })\n",
    "\n",
    "agreement_df = pd.DataFrame(agreement_results)\n",
    "print(agreement_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdbe1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation coefficients\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CORRELATION ANALYSIS BETWEEN MODELS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "correlation_results = []\n",
    "\n",
    "for aspect, df_comp in model_comparisons.items():\n",
    "    pearson_corr, pearson_p = pearsonr(df_comp['Sentiment_Label_tiny'], \n",
    "                                        df_comp['Sentiment_Label_distil'])\n",
    "    spearman_corr, spearman_p = spearmanr(df_comp['Sentiment_Label_tiny'], \n",
    "                                           df_comp['Sentiment_Label_distil'])\n",
    "    \n",
    "    correlation_results.append({\n",
    "        'Aspect': aspect,\n",
    "        'Pearson_Correlation': round(pearson_corr, 4),\n",
    "        'Pearson_p_value': f\"{pearson_p:.2e}\",\n",
    "        'Spearman_Correlation': round(spearman_corr, 4),\n",
    "        'Spearman_p_value': f\"{spearman_p:.2e}\"\n",
    "    })\n",
    "\n",
    "correlation_df = pd.DataFrame(correlation_results)\n",
    "print(correlation_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c872d310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrices for model comparison\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "fig.suptitle('Model Prediction Comparison - Confusion Matrices', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, (aspect, df_comp) in enumerate(model_comparisons.items()):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Create confusion matrix\n",
    "    confusion = pd.crosstab(df_comp['Sentiment_Label_tiny'], \n",
    "                            df_comp['Sentiment_Label_distil'],\n",
    "                            rownames=['TinyRoBERTa'],\n",
    "                            colnames=['DistilBERT'])\n",
    "    \n",
    "    sns.heatmap(confusion, annot=True, fmt='d', cmap='YlOrRd', ax=ax, cbar_kws={'label': 'Count'})\n",
    "    ax.set_title(f'{aspect}', fontweight='bold')\n",
    "    ax.set_xlabel('DistilBERT Prediction', fontsize=11)\n",
    "    ax.set_ylabel('TinyRoBERTa Prediction', fontsize=11)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bc9f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive scatter plot comparing models\n",
    "fig = make_subplots(\n",
    "    rows=1, cols=3,\n",
    "    subplot_titles=list(model_comparisons.keys()),\n",
    "    specs=[[{'type':'scatter'}]*3]\n",
    ")\n",
    "\n",
    "colors_map = {'Food': 'red', 'Service': 'blue', 'Ambiance': 'green'}\n",
    "\n",
    "for idx, (aspect, df_comp) in enumerate(model_comparisons.items()):\n",
    "    # Add scatter plot\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=df_comp['Sentiment_Label_tiny'],\n",
    "            y=df_comp['Sentiment_Label_distil'],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                size=5,\n",
    "                color=colors_map[aspect],\n",
    "                opacity=0.5\n",
    "            ),\n",
    "            name=aspect,\n",
    "            text=[f\"Tiny: {t}<br>Distil: {d}\" for t, d in \n",
    "                  zip(df_comp['Sentiment_Label_tiny'], df_comp['Sentiment_Label_distil'])],\n",
    "            hovertemplate='%{text}<extra></extra>'\n",
    "        ),\n",
    "        row=1, col=idx+1\n",
    "    )\n",
    "    \n",
    "    # Add diagonal line (perfect agreement)\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=[1, 5],\n",
    "            y=[1, 5],\n",
    "            mode='lines',\n",
    "            line=dict(color='black', dash='dash'),\n",
    "            showlegend=False\n",
    "        ),\n",
    "        row=1, col=idx+1\n",
    "    )\n",
    "\n",
    "fig.update_xaxes(title_text=\"TinyRoBERTa Prediction\", row=1, col=1)\n",
    "fig.update_xaxes(title_text=\"TinyRoBERTa Prediction\", row=1, col=2)\n",
    "fig.update_xaxes(title_text=\"TinyRoBERTa Prediction\", row=1, col=3)\n",
    "fig.update_yaxes(title_text=\"DistilBERT Prediction\", row=1, col=1)\n",
    "\n",
    "fig.update_layout(\n",
    "    title_text=\"Model Prediction Comparison - Scatter Plots\",\n",
    "    height=500,\n",
    "    showlegend=True\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f869fa17",
   "metadata": {},
   "source": [
    "## 5. Aspect-Based Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5036a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average sentiment by aspect\n",
    "aspect_stats = df_all.groupby(['Aspect', 'Model'])['Sentiment_Label'].agg([\n",
    "    'mean', 'median', 'std', 'min', 'max', 'count'\n",
    "]).round(3)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SENTIMENT STATISTICS BY ASPECT AND MODEL\")\n",
    "print(\"=\" * 80)\n",
    "print(aspect_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fefc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouped bar chart comparing average ratings\n",
    "aspect_avg = df_all.groupby(['Aspect', 'Model'])['Sentiment_Label'].mean().reset_index()\n",
    "aspect_avg_pivot = aspect_avg.pivot(index='Aspect', columns='Model', values='Sentiment_Label')\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "aspect_avg_pivot.plot(kind='bar', ax=ax, width=0.7)\n",
    "ax.set_title('Average Sentiment Rating by Aspect and Model', fontsize=14, fontweight='bold')\n",
    "ax.set_xlabel('Aspect', fontsize=12)\n",
    "ax.set_ylabel('Average Sentiment (1-5 Stars)', fontsize=12)\n",
    "ax.legend(title='Model', title_fontsize=11, fontsize=10)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim([0, 5])\n",
    "plt.xticks(rotation=0)\n",
    "\n",
    "# Add value labels\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='%.2f', padding=3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df2d1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution comparison across aspects\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5), sharey=True)\n",
    "fig.suptitle('Sentiment Distribution by Aspect (Both Models Combined)', fontsize=16, fontweight='bold')\n",
    "\n",
    "aspects = ['Food', 'Service', 'Ambiance']\n",
    "colors_list = ['#e74c3c', '#3498db', '#2ecc71']\n",
    "\n",
    "for idx, aspect in enumerate(aspects):\n",
    "    ax = axes[idx]\n",
    "    data = df_all[df_all['Aspect'] == aspect]['Sentiment_Label']\n",
    "    \n",
    "    ax.hist(data, bins=[0.5, 1.5, 2.5, 3.5, 4.5, 5.5], \n",
    "            edgecolor='black', alpha=0.7, color=colors_list[idx])\n",
    "    ax.set_title(aspect, fontweight='bold', fontsize=13)\n",
    "    ax.set_xlabel('Sentiment Label (Stars)', fontsize=11)\n",
    "    ax.set_xticks([1, 2, 3, 4, 5])\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add statistics text\n",
    "    mean_val = data.mean()\n",
    "    median_val = data.median()\n",
    "    ax.text(0.98, 0.97, f'Mean: {mean_val:.2f}\\nMedian: {median_val:.1f}',\n",
    "            transform=ax.transAxes, fontsize=10,\n",
    "            verticalalignment='top', horizontalalignment='right',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "axes[0].set_ylabel('Frequency', fontsize=11)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764a2f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for sentiment distribution\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "data_for_box = []\n",
    "labels_for_box = []\n",
    "\n",
    "for aspect in ['Food', 'Service', 'Ambiance']:\n",
    "    for model in ['TinyRoBERTa', 'DistilBERT']:\n",
    "        data = df_all[(df_all['Aspect'] == aspect) & (df_all['Model'] == model)]['Sentiment_Label']\n",
    "        data_for_box.append(data)\n",
    "        labels_for_box.append(f\"{aspect}\\n{model}\")\n",
    "\n",
    "bp = ax.boxplot(data_for_box, labels=labels_for_box, patch_artist=True,\n",
    "                showmeans=True, meanline=True)\n",
    "\n",
    "# Color the boxes\n",
    "colors = ['#ffcccc', '#ffaaaa', '#ccddff', '#aaccff', '#ccffcc', '#aaffaa']\n",
    "for patch, color in zip(bp['boxes'], colors):\n",
    "    patch.set_facecolor(color)\n",
    "\n",
    "ax.set_title('Sentiment Distribution Box Plots by Aspect and Model', fontsize=14, fontweight='bold')\n",
    "ax.set_ylabel('Sentiment Label (Stars)', fontsize=12)\n",
    "ax.set_xlabel('Aspect and Model', fontsize=12)\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "ax.set_ylim([0, 6])\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3903761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive radar chart for aspect comparison\n",
    "categories = ['1 Star', '2 Stars', '3 Stars', '4 Stars', '5 Stars']\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for aspect in ['Food', 'Service', 'Ambiance']:\n",
    "    data = df_all[df_all['Aspect'] == aspect]['Sentiment_Label'].value_counts().sort_index()\n",
    "    # Normalize to percentages\n",
    "    data_pct = (data / data.sum() * 100).reindex([1, 2, 3, 4, 5], fill_value=0)\n",
    "    \n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=data_pct.values,\n",
    "        theta=categories,\n",
    "        fill='toself',\n",
    "        name=aspect\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    polar=dict(\n",
    "        radialaxis=dict(\n",
    "            visible=True,\n",
    "            range=[0, max([df_all[df_all['Aspect'] == a]['Sentiment_Label'].value_counts().max() \n",
    "                          / len(df_all[df_all['Aspect'] == a]) * 100 for a in ['Food', 'Service', 'Ambiance']])]\n",
    "        )\n",
    "    ),\n",
    "    showlegend=True,\n",
    "    title=\"Aspect Sentiment Distribution Comparison (Radar Chart)\"\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a559c898",
   "metadata": {},
   "source": [
    "## 6. Geographic Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca549cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if City column exists\n",
    "if 'City' in df_all.columns:\n",
    "    print(\"✓ City column found!\")\n",
    "    city_analysis = True\n",
    "    print(f\"\\nUnique cities: {df_all['City'].nunique()}\")\n",
    "    print(f\"\\nTop 10 cities by review count:\")\n",
    "    print(df_all['City'].value_counts().head(10))\n",
    "else:\n",
    "    print(\"⚠ City column not found in dataset\")\n",
    "    print(\"Available columns:\", df_all.columns.tolist())\n",
    "    city_analysis = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5db4bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if city_analysis:\n",
    "    # Average sentiment by city (top 20 cities)\n",
    "    city_sentiment = df_all.groupby('City').agg({\n",
    "        'Sentiment_Label': ['mean', 'count']\n",
    "    }).round(2)\n",
    "    city_sentiment.columns = ['Avg_Sentiment', 'Review_Count']\n",
    "    city_sentiment = city_sentiment[city_sentiment['Review_Count'] >= 30]  # Filter cities with at least 30 reviews\n",
    "    city_sentiment = city_sentiment.sort_values('Avg_Sentiment', ascending=False).head(20)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"TOP 20 CITIES BY AVERAGE SENTIMENT (min 30 reviews)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(city_sentiment)\n",
    "    \n",
    "    # Visualization\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "    bars = ax.barh(range(len(city_sentiment)), city_sentiment['Avg_Sentiment'], color='skyblue', edgecolor='navy')\n",
    "    ax.set_yticks(range(len(city_sentiment)))\n",
    "    ax.set_yticklabels(city_sentiment.index)\n",
    "    ax.set_xlabel('Average Sentiment Rating', fontsize=12)\n",
    "    ax.set_title('Top 20 Cities by Average Sentiment Rating', fontsize=14, fontweight='bold')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (idx, row) in enumerate(city_sentiment.iterrows()):\n",
    "        ax.text(row['Avg_Sentiment'] + 0.02, i, f\"{row['Avg_Sentiment']:.2f} ({int(row['Review_Count'])})\", \n",
    "                va='center', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping geographic analysis - City column not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a980dbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if city_analysis:\n",
    "    # Sentiment distribution by city (top 10 cities)\n",
    "    top_cities = df_all['City'].value_counts().head(10).index\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 5, figsize=(20, 8))\n",
    "    fig.suptitle('Sentiment Distribution in Top 10 Cities', fontsize=16, fontweight='bold')\n",
    "    \n",
    "    for idx, city in enumerate(top_cities):\n",
    "        row = idx // 5\n",
    "        col = idx % 5\n",
    "        ax = axes[row, col]\n",
    "        \n",
    "        city_data = df_all[df_all['City'] == city]['Sentiment_Label']\n",
    "        counts = city_data.value_counts().sort_index()\n",
    "        \n",
    "        ax.bar(counts.index, counts.values, color='coral', edgecolor='black', alpha=0.7)\n",
    "        ax.set_title(city, fontweight='bold')\n",
    "        ax.set_xlabel('Rating')\n",
    "        ax.set_ylabel('Count')\n",
    "        ax.set_xticks([1, 2, 3, 4, 5])\n",
    "        ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4593002c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if city_analysis:\n",
    "    # Aspect-specific sentiment by city\n",
    "    city_aspect = df_all.groupby(['City', 'Aspect'])['Sentiment_Label'].mean().reset_index()\n",
    "    city_aspect_pivot = city_aspect.pivot(index='City', columns='Aspect', values='Sentiment_Label')\n",
    "    \n",
    "    # Filter cities with sufficient data\n",
    "    city_counts = df_all.groupby('City').size()\n",
    "    cities_to_show = city_counts[city_counts >= 50].index\n",
    "    city_aspect_pivot = city_aspect_pivot.loc[cities_to_show].head(15)\n",
    "    \n",
    "    # Create heatmap\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    sns.heatmap(city_aspect_pivot, annot=True, fmt='.2f', cmap='RdYlGn', \n",
    "                center=3, vmin=1, vmax=5, ax=ax, cbar_kws={'label': 'Average Sentiment'})\n",
    "    ax.set_title('Average Sentiment by City and Aspect (Top 15 Cities)', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Aspect', fontsize=12)\n",
    "    ax.set_ylabel('City', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "987a65eb",
   "metadata": {},
   "source": [
    "## 7. Rating vs Sentiment Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae34b2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for similarity score columns\n",
    "similarity_cols = [col for col in df_all.columns if 'similarity' in col.lower() or 'score' in col.lower()]\n",
    "print(\"Columns related to similarity/scores:\")\n",
    "print(similarity_cols)\n",
    "\n",
    "# Check specific aspect similarity columns\n",
    "aspect_similarity_col = None\n",
    "for col in df_all.columns:\n",
    "    if 'aspect' in col.lower() and 'sim' in col.lower():\n",
    "        aspect_similarity_col = col\n",
    "        break\n",
    "\n",
    "if aspect_similarity_col:\n",
    "    print(f\"\\n✓ Found aspect similarity column: {aspect_similarity_col}\")\n",
    "else:\n",
    "    print(\"\\n⚠ Aspect similarity column not found. Available columns:\")\n",
    "    print(df_all.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9193fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze relationship between aspect similarity and sentiment\n",
    "if 'Aspect_Similarity_Score' in df_all.columns:\n",
    "    similarity_col = 'Aspect_Similarity_Score'\n",
    "elif len([col for col in df_all.columns if 'similarity' in col.lower()]) > 0:\n",
    "    similarity_col = [col for col in df_all.columns if 'similarity' in col.lower()][0]\n",
    "else:\n",
    "    similarity_col = None\n",
    "\n",
    "if similarity_col:\n",
    "    print(f\"Analyzing: {similarity_col}\")\n",
    "    \n",
    "    # Calculate correlation\n",
    "    correlation, p_value = pearsonr(df_all[similarity_col].dropna(), \n",
    "                                     df_all.loc[df_all[similarity_col].notna(), 'Sentiment_Label'])\n",
    "    \n",
    "    print(f\"\\nPearson Correlation: {correlation:.4f}\")\n",
    "    print(f\"P-value: {p_value:.2e}\")\n",
    "    \n",
    "    # Scatter plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    for aspect in ['Food', 'Service', 'Ambiance']:\n",
    "        data = df_all[df_all['Aspect'] == aspect]\n",
    "        ax.scatter(data[similarity_col], data['Sentiment_Label'], \n",
    "                  alpha=0.3, label=aspect, s=20)\n",
    "    \n",
    "    ax.set_xlabel(similarity_col, fontsize=12)\n",
    "    ax.set_ylabel('Sentiment Label', fontsize=12)\n",
    "    ax.set_title(f'Relationship between {similarity_col} and Sentiment\\n(Correlation: {correlation:.4f})', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "    ax.legend()\n",
    "    ax.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Box plot: Sentiment by similarity score bins\n",
    "    df_all['Similarity_Bin'] = pd.cut(df_all[similarity_col], bins=5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    df_all.boxplot(column='Sentiment_Label', by='Similarity_Bin', ax=ax)\n",
    "    ax.set_title('Sentiment Distribution by Aspect Similarity Level', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Aspect Similarity Level', fontsize=12)\n",
    "    ax.set_ylabel('Sentiment Label', fontsize=12)\n",
    "    plt.suptitle('')  # Remove default title\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Skipping similarity analysis - no similarity column found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda9e517",
   "metadata": {},
   "source": [
    "## 8. Text Length and Sentiment Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1790bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate text length\n",
    "if 'Review_Text' in df_all.columns:\n",
    "    df_all['Review_Length'] = df_all['Review_Text'].astype(str).str.len()\n",
    "    df_all['Word_Count'] = df_all['Review_Text'].astype(str).str.split().str.len()\n",
    "    \n",
    "    print(\"✓ Text length metrics calculated!\")\n",
    "    print(\"\\nText Length Statistics:\")\n",
    "    print(df_all[['Review_Length', 'Word_Count']].describe())\n",
    "else:\n",
    "    text_col = None\n",
    "    for col in df_all.columns:\n",
    "        if 'text' in col.lower() or 'review' in col.lower():\n",
    "            text_col = col\n",
    "            break\n",
    "    \n",
    "    if text_col:\n",
    "        print(f\"✓ Using column: {text_col}\")\n",
    "        df_all['Review_Length'] = df_all[text_col].astype(str).str.len()\n",
    "        df_all['Word_Count'] = df_all[text_col].astype(str).str.split().str.len()\n",
    "        print(\"\\nText Length Statistics:\")\n",
    "        print(df_all[['Review_Length', 'Word_Count']].describe())\n",
    "    else:\n",
    "        print(\"⚠ No text column found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a9d2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Review_Length' in df_all.columns:\n",
    "    # Scatter plot: Review length vs sentiment\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Character length\n",
    "    for aspect in ['Food', 'Service', 'Ambiance']:\n",
    "        data = df_all[df_all['Aspect'] == aspect]\n",
    "        axes[0].scatter(data['Review_Length'], data['Sentiment_Label'], \n",
    "                       alpha=0.3, label=aspect, s=15)\n",
    "    \n",
    "    axes[0].set_xlabel('Review Length (Characters)', fontsize=12)\n",
    "    axes[0].set_ylabel('Sentiment Label', fontsize=12)\n",
    "    axes[0].set_title('Review Length vs Sentiment', fontsize=13, fontweight='bold')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(alpha=0.3)\n",
    "    \n",
    "    # Word count\n",
    "    for aspect in ['Food', 'Service', 'Ambiance']:\n",
    "        data = df_all[df_all['Aspect'] == aspect]\n",
    "        axes[1].scatter(data['Word_Count'], data['Sentiment_Label'], \n",
    "                       alpha=0.3, label=aspect, s=15)\n",
    "    \n",
    "    axes[1].set_xlabel('Word Count', fontsize=12)\n",
    "    axes[1].set_ylabel('Sentiment Label', fontsize=12)\n",
    "    axes[1].set_title('Word Count vs Sentiment', fontsize=13, fontweight='bold')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate correlations\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"CORRELATION: TEXT LENGTH AND SENTIMENT\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    for aspect in ['Food', 'Service', 'Ambiance']:\n",
    "        data = df_all[df_all['Aspect'] == aspect]\n",
    "        corr_len, p_len = pearsonr(data['Review_Length'].dropna(), \n",
    "                                    data.loc[data['Review_Length'].notna(), 'Sentiment_Label'])\n",
    "        corr_word, p_word = pearsonr(data['Word_Count'].dropna(), \n",
    "                                     data.loc[data['Word_Count'].notna(), 'Sentiment_Label'])\n",
    "        \n",
    "        print(f\"\\n{aspect}:\")\n",
    "        print(f\"  Review Length correlation: {corr_len:.4f} (p={p_len:.4f})\")\n",
    "        print(f\"  Word Count correlation: {corr_word:.4f} (p={p_word:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b8fdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Review_Length' in df_all.columns:\n",
    "    # Box plots: Sentiment by text length quartiles\n",
    "    df_all['Length_Quartile'] = pd.qcut(df_all['Review_Length'], q=4, labels=['Q1 (Short)', 'Q2', 'Q3', 'Q4 (Long)'])\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    data_for_box = [df_all[df_all['Length_Quartile'] == q]['Sentiment_Label'].values \n",
    "                    for q in ['Q1 (Short)', 'Q2', 'Q3', 'Q4 (Long)']]\n",
    "    \n",
    "    bp = ax.boxplot(data_for_box, labels=['Q1 (Short)', 'Q2', 'Q3', 'Q4 (Long)'], \n",
    "                    patch_artist=True, showmeans=True)\n",
    "    \n",
    "    colors = ['#ff9999', '#ffcc99', '#99ccff', '#99ff99']\n",
    "    for patch, color in zip(bp['boxes'], colors):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    ax.set_title('Sentiment Distribution by Review Length Quartile', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Review Length Quartile', fontsize=12)\n",
    "    ax.set_ylabel('Sentiment Label', fontsize=12)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb7d4cf",
   "metadata": {},
   "source": [
    "## 9. Confidence Score Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c52fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for confidence score columns\n",
    "confidence_cols = [col for col in df_all.columns if 'confidence' in col.lower()]\n",
    "print(\"Confidence-related columns:\")\n",
    "print(confidence_cols)\n",
    "\n",
    "if len(confidence_cols) > 0:\n",
    "    confidence_col = confidence_cols[0]\n",
    "    print(f\"\\n✓ Using confidence column: {confidence_col}\")\n",
    "    \n",
    "    print(\"\\nConfidence Score Statistics:\")\n",
    "    print(df_all[confidence_col].describe())\n",
    "else:\n",
    "    print(\"\\n⚠ No confidence column found\")\n",
    "    confidence_col = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff01e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if confidence_col:\n",
    "    # Confidence distribution by model\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "    \n",
    "    for idx, model in enumerate(['TinyRoBERTa', 'DistilBERT']):\n",
    "        data = df_all[df_all['Model'] == model][confidence_col]\n",
    "        \n",
    "        axes[idx].hist(data, bins=50, edgecolor='black', alpha=0.7, color='steelblue')\n",
    "        axes[idx].set_title(f'{model} Confidence Score Distribution', fontweight='bold', fontsize=13)\n",
    "        axes[idx].set_xlabel('Confidence Score', fontsize=11)\n",
    "        axes[idx].set_ylabel('Frequency', fontsize=11)\n",
    "        axes[idx].axvline(data.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {data.mean():.3f}')\n",
    "        axes[idx].axvline(data.median(), color='green', linestyle='--', linewidth=2, label=f'Median: {data.median():.3f}')\n",
    "        axes[idx].legend()\n",
    "        axes[idx].grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aebccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "if confidence_col:\n",
    "    # Confidence by sentiment label\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    sentiment_labels = sorted(df_all['Sentiment_Label'].unique())\n",
    "    data_by_sentiment = [df_all[df_all['Sentiment_Label'] == label][confidence_col].values \n",
    "                         for label in sentiment_labels]\n",
    "    \n",
    "    bp = ax.boxplot(data_by_sentiment, labels=[f'{int(x)} Star' for x in sentiment_labels],\n",
    "                    patch_artist=True, showmeans=True)\n",
    "    \n",
    "    colors = ['#d62728', '#ff7f0e', '#bcbd22', '#2ca02c', '#17becf']\n",
    "    for patch, color in zip(bp['boxes'], colors[:len(sentiment_labels)]):\n",
    "        patch.set_facecolor(color)\n",
    "    \n",
    "    ax.set_title('Confidence Score Distribution by Sentiment Label', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Sentiment Label', fontsize=12)\n",
    "    ax.set_ylabel('Confidence Score', fontsize=12)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistics\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"AVERAGE CONFIDENCE BY SENTIMENT LABEL\")\n",
    "    print(\"=\" * 80)\n",
    "    conf_by_sentiment = df_all.groupby('Sentiment_Label')[confidence_col].agg(['mean', 'std', 'count']).round(4)\n",
    "    print(conf_by_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7f3cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if confidence_col:\n",
    "    # Identify low confidence predictions\n",
    "    low_confidence_threshold = df_all[confidence_col].quantile(0.1)\n",
    "    print(f\"Low confidence threshold (10th percentile): {low_confidence_threshold:.4f}\")\n",
    "    \n",
    "    low_conf = df_all[df_all[confidence_col] < low_confidence_threshold]\n",
    "    print(f\"\\nNumber of low confidence predictions: {len(low_conf)} ({len(low_conf)/len(df_all)*100:.2f}%)\")\n",
    "    \n",
    "    print(\"\\nLow Confidence Distribution by Aspect and Model:\")\n",
    "    print(low_conf.groupby(['Aspect', 'Model']).size())\n",
    "    \n",
    "    # Visualize\n",
    "    low_conf_dist = low_conf.groupby(['Aspect', 'Model']).size().reset_index(name='Count')\n",
    "    \n",
    "    fig = px.bar(low_conf_dist, x='Aspect', y='Count', color='Model', \n",
    "                 barmode='group',\n",
    "                 title=f'Low Confidence Predictions Distribution (Confidence < {low_confidence_threshold:.4f})',\n",
    "                 labels={'Count': 'Number of Predictions'},\n",
    "                 color_discrete_map={'TinyRoBERTa': '#ff6b6b', 'DistilBERT': '#4ecdc4'})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e60469",
   "metadata": {},
   "outputs": [],
   "source": [
    "if confidence_col:\n",
    "    # Confidence vs sentiment scatter (with aspect colors)\n",
    "    fig = px.scatter(df_all.sample(5000), \n",
    "                     x=confidence_col, \n",
    "                     y='Sentiment_Label',\n",
    "                     color='Aspect',\n",
    "                     facet_col='Model',\n",
    "                     opacity=0.5,\n",
    "                     title='Confidence Score vs Sentiment Label',\n",
    "                     labels={confidence_col: 'Confidence Score', 'Sentiment_Label': 'Sentiment'},\n",
    "                     color_discrete_map={'Food': '#e74c3c', 'Service': '#3498db', 'Ambiance': '#2ecc71'})\n",
    "    fig.update_yaxes(dtick=1)\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2ddce6",
   "metadata": {},
   "source": [
    "## 10. Language Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c08f02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check language column\n",
    "if 'Language' in df_all.columns or 'language' in df_all.columns:\n",
    "    lang_col = 'Language' if 'Language' in df_all.columns else 'language'\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"LANGUAGE DISTRIBUTION\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    print(\"\\nLanguage counts:\")\n",
    "    lang_counts = df_all[lang_col].value_counts()\n",
    "    print(lang_counts)\n",
    "    \n",
    "    # Visualization\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    lang_counts.plot(kind='bar', ax=ax, color='teal', edgecolor='black')\n",
    "    ax.set_title('Language Distribution in Dataset', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Language', fontsize=12)\n",
    "    ax.set_ylabel('Count', fontsize=12)\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    for i, v in enumerate(lang_counts):\n",
    "        ax.text(i, v + 10, str(v), ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Sentiment by language\n",
    "    if len(lang_counts) > 1:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"SENTIMENT STATISTICS BY LANGUAGE\")\n",
    "        print(\"=\" * 80)\n",
    "        lang_sentiment = df_all.groupby(lang_col)['Sentiment_Label'].agg(['mean', 'std', 'count']).round(3)\n",
    "        print(lang_sentiment)\n",
    "else:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"LANGUAGE ANALYSIS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(\"⚠ Language column not found in dataset\")\n",
    "    print(\"Note: Current dataset appears to be monolingual (English)\")\n",
    "    print(\"\\nFramework is ready for multi-language analysis when data becomes available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e86cb09",
   "metadata": {},
   "source": [
    "## 11. Restaurant-Level Insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b4781f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for restaurant identifier\n",
    "restaurant_col = None\n",
    "for col in ['Restaurant_id', 'restaurant_id', 'Restaurant_ID', 'RestaurantID']:\n",
    "    if col in df_all.columns:\n",
    "        restaurant_col = col\n",
    "        break\n",
    "\n",
    "if restaurant_col:\n",
    "    print(f\"✓ Restaurant identifier found: {restaurant_col}\")\n",
    "    print(f\"Total unique restaurants: {df_all[restaurant_col].nunique()}\")\n",
    "    \n",
    "    # Reviews per restaurant\n",
    "    reviews_per_restaurant = df_all[restaurant_col].value_counts()\n",
    "    print(f\"\\nRestaurants with most reviews:\")\n",
    "    print(reviews_per_restaurant.head(10))\n",
    "else:\n",
    "    print(\"⚠ Restaurant identifier column not found\")\n",
    "    print(\"Available columns:\", df_all.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918cc4db",
   "metadata": {},
   "outputs": [],
   "source": [
    "if restaurant_col:\n",
    "    # Average sentiment by restaurant\n",
    "    restaurant_sentiment = df_all.groupby([restaurant_col, 'Aspect'])['Sentiment_Label'].agg([\n",
    "        'mean', 'std', 'count'\n",
    "    ]).round(3)\n",
    "    restaurant_sentiment.columns = ['Avg_Sentiment', 'Std_Dev', 'Review_Count']\n",
    "    \n",
    "    # Filter restaurants with at least 5 reviews per aspect\n",
    "    restaurant_sentiment = restaurant_sentiment[restaurant_sentiment['Review_Count'] >= 5]\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"RESTAURANT PERFORMANCE SUMMARY (min 5 reviews per aspect)\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\nTotal qualifying restaurants: {restaurant_sentiment.index.get_level_values(0).nunique()}\")\n",
    "    \n",
    "    # Top performers by aspect\n",
    "    for aspect in ['Food', 'Service', 'Ambiance']:\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"TOP 10 RESTAURANTS - {aspect.upper()}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        aspect_data = restaurant_sentiment.xs(aspect, level='Aspect').sort_values('Avg_Sentiment', ascending=False).head(10)\n",
    "        print(aspect_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8023f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if restaurant_col:\n",
    "    # Overall restaurant rankings (average across all aspects)\n",
    "    overall_restaurant = df_all.groupby(restaurant_col)['Sentiment_Label'].agg([\n",
    "        'mean', 'std', 'count'\n",
    "    ]).round(3)\n",
    "    overall_restaurant.columns = ['Avg_Sentiment', 'Std_Dev', 'Review_Count']\n",
    "    overall_restaurant = overall_restaurant[overall_restaurant['Review_Count'] >= 15]  # At least 15 total reviews\n",
    "    overall_restaurant = overall_restaurant.sort_values('Avg_Sentiment', ascending=False)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"OVERALL TOP 20 RESTAURANTS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(overall_restaurant.head(20))\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"OVERALL BOTTOM 20 RESTAURANTS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(overall_restaurant.tail(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dbe08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if restaurant_col:\n",
    "    # Visualize top 15 restaurants\n",
    "    top_15 = overall_restaurant.head(15)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    bars = ax.barh(range(len(top_15)), top_15['Avg_Sentiment'], color='gold', edgecolor='darkgoldenrod')\n",
    "    ax.set_yticks(range(len(top_15)))\n",
    "    ax.set_yticklabels([f\"Restaurant {rid}\" for rid in top_15.index])\n",
    "    ax.set_xlabel('Average Sentiment Rating', fontsize=12)\n",
    "    ax.set_title('Top 15 Restaurants by Average Sentiment', fontsize=14, fontweight='bold')\n",
    "    ax.grid(axis='x', alpha=0.3)\n",
    "    ax.set_xlim([0, 5])\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (idx, row) in enumerate(top_15.iterrows()):\n",
    "        ax.text(row['Avg_Sentiment'] + 0.05, i, \n",
    "                f\"{row['Avg_Sentiment']:.2f} ({int(row['Review_Count'])} reviews)\", \n",
    "                va='center', fontsize=9)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bed5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if restaurant_col:\n",
    "    # Aspect breakdown for top restaurants\n",
    "    top_10_ids = overall_restaurant.head(10).index\n",
    "    \n",
    "    aspect_breakdown = df_all[df_all[restaurant_col].isin(top_10_ids)].groupby([restaurant_col, 'Aspect'])['Sentiment_Label'].mean().reset_index()\n",
    "    aspect_breakdown_pivot = aspect_breakdown.pivot(index=restaurant_col, columns='Aspect', values='Sentiment_Label')\n",
    "    \n",
    "    # Create heatmap\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    sns.heatmap(aspect_breakdown_pivot, annot=True, fmt='.2f', cmap='RdYlGn', \n",
    "                center=3, vmin=1, vmax=5, ax=ax, cbar_kws={'label': 'Average Sentiment'})\n",
    "    ax.set_title('Aspect-Level Performance of Top 10 Restaurants', fontsize=14, fontweight='bold')\n",
    "    ax.set_xlabel('Aspect', fontsize=12)\n",
    "    ax.set_ylabel('Restaurant ID', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbda3d1",
   "metadata": {},
   "source": [
    "## 12. Word Cloud and Topic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846bb5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install wordcloud if needed (uncomment if necessary)\n",
    "# !pip install wordcloud\n",
    "\n",
    "try:\n",
    "    from wordcloud import WordCloud\n",
    "    import re\n",
    "    wordcloud_available = True\n",
    "    print(\"✓ WordCloud library available\")\n",
    "except ImportError:\n",
    "    print(\"⚠ WordCloud library not available. Install with: pip install wordcloud\")\n",
    "    wordcloud_available = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde35c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if wordcloud_available and 'Review_Text' in df_all.columns:\n",
    "    # Function to clean text\n",
    "    def clean_text(text):\n",
    "        text = str(text).lower()\n",
    "        text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "        return text\n",
    "    \n",
    "    # Generate word clouds for positive and negative reviews\n",
    "    positive_reviews = df_all[df_all['Sentiment_Label'] >= 4]['Review_Text'].apply(clean_text)\n",
    "    negative_reviews = df_all[df_all['Sentiment_Label'] <= 2]['Review_Text'].apply(clean_text)\n",
    "    \n",
    "    positive_text = ' '.join(positive_reviews.astype(str))\n",
    "    negative_text = ' '.join(negative_reviews.astype(str))\n",
    "    \n",
    "    # Create word clouds\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "    \n",
    "    # Positive reviews\n",
    "    wordcloud_pos = WordCloud(width=800, height=400, background_color='white', \n",
    "                              colormap='Greens', max_words=100).generate(positive_text)\n",
    "    axes[0].imshow(wordcloud_pos, interpolation='bilinear')\n",
    "    axes[0].set_title('Positive Reviews (4-5 Stars)\\nMost Common Words', fontsize=14, fontweight='bold')\n",
    "    axes[0].axis('off')\n",
    "    \n",
    "    # Negative reviews\n",
    "    wordcloud_neg = WordCloud(width=800, height=400, background_color='white', \n",
    "                              colormap='Reds', max_words=100).generate(negative_text)\n",
    "    axes[1].imshow(wordcloud_neg, interpolation='bilinear')\n",
    "    axes[1].set_title('Negative Reviews (1-2 Stars)\\nMost Common Words', fontsize=14, fontweight='bold')\n",
    "    axes[1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✓ Word clouds generated successfully!\")\n",
    "elif not wordcloud_available:\n",
    "    print(\"Skipping word cloud generation - library not available\")\n",
    "else:\n",
    "    print(\"Skipping word cloud generation - Review_Text column not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde302aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if wordcloud_available and 'Review_Text' in df_all.columns:\n",
    "    # Aspect-specific word clouds\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(18, 20))\n",
    "    fig.suptitle('Aspect-Specific Word Clouds (Positive vs Negative)', fontsize=16, fontweight='bold', y=0.995)\n",
    "    \n",
    "    for idx, aspect in enumerate(['Food', 'Service', 'Ambiance']):\n",
    "        aspect_data = df_all[df_all['Aspect'] == aspect]\n",
    "        \n",
    "        # Positive\n",
    "        pos_text = ' '.join(aspect_data[aspect_data['Sentiment_Label'] >= 4]['Review_Text'].apply(clean_text).astype(str))\n",
    "        wordcloud_pos = WordCloud(width=700, height=350, background_color='white', \n",
    "                                  colormap='Greens', max_words=80).generate(pos_text)\n",
    "        axes[idx, 0].imshow(wordcloud_pos, interpolation='bilinear')\n",
    "        axes[idx, 0].set_title(f'{aspect} - Positive (4-5 Stars)', fontsize=12, fontweight='bold')\n",
    "        axes[idx, 0].axis('off')\n",
    "        \n",
    "        # Negative\n",
    "        neg_text = ' '.join(aspect_data[aspect_data['Sentiment_Label'] <= 2]['Review_Text'].apply(clean_text).astype(str))\n",
    "        wordcloud_neg = WordCloud(width=700, height=350, background_color='white', \n",
    "                                  colormap='Reds', max_words=80).generate(neg_text)\n",
    "        axes[idx, 1].imshow(wordcloud_neg, interpolation='bilinear')\n",
    "        axes[idx, 1].set_title(f'{aspect} - Negative (1-2 Stars)', fontsize=12, fontweight='bold')\n",
    "        axes[idx, 1].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641a4640",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Review_Text' in df_all.columns:\n",
    "    # Most common words analysis using simple counting\n",
    "    from collections import Counter\n",
    "    import string\n",
    "    \n",
    "    # Common stop words\n",
    "    stop_words = set(['the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', \n",
    "                      'of', 'with', 'by', 'from', 'as', 'is', 'was', 'are', 'were', 'been',\n",
    "                      'be', 'have', 'has', 'had', 'do', 'does', 'did', 'will', 'would', 'could',\n",
    "                      'should', 'may', 'might', 'must', 'can', 'this', 'that', 'these', 'those',\n",
    "                      'i', 'you', 'he', 'she', 'it', 'we', 'they', 'my', 'your', 'his', 'her',\n",
    "                      'its', 'our', 'their', 'me', 'him', 'us', 'them'])\n",
    "    \n",
    "    def extract_words(text_series):\n",
    "        words = []\n",
    "        for text in text_series:\n",
    "            text = str(text).lower()\n",
    "            text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "            words.extend([w for w in text.split() if w not in stop_words and len(w) > 2])\n",
    "        return Counter(words)\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"TOP 20 WORDS IN POSITIVE VS NEGATIVE REVIEWS\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Positive reviews\n",
    "    pos_words = extract_words(df_all[df_all['Sentiment_Label'] >= 4]['Review_Text'])\n",
    "    print(\"\\nPOSITIVE REVIEWS (4-5 Stars):\")\n",
    "    for word, count in pos_words.most_common(20):\n",
    "        print(f\"  {word:.<20} {count}\")\n",
    "    \n",
    "    # Negative reviews\n",
    "    neg_words = extract_words(df_all[df_all['Sentiment_Label'] <= 2]['Review_Text'])\n",
    "    print(\"\\nNEGATIVE REVIEWS (1-2 Stars):\")\n",
    "    for word, count in neg_words.most_common(20):\n",
    "        print(f\"  {word:.<20} {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b607f3d2",
   "metadata": {},
   "source": [
    "## 13. Statistical Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b938d870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T-test: Compare sentiment between models\n",
    "print(\"=\" * 80)\n",
    "print(\"T-TEST: MODEL COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for aspect in ['Food', 'Service', 'Ambiance']:\n",
    "    tiny_data = df_all[(df_all['Aspect'] == aspect) & (df_all['Model'] == 'TinyRoBERTa')]['Sentiment_Label']\n",
    "    distil_data = df_all[(df_all['Aspect'] == aspect) & (df_all['Model'] == 'DistilBERT')]['Sentiment_Label']\n",
    "    \n",
    "    t_stat, p_value = stats.ttest_ind(tiny_data, distil_data)\n",
    "    \n",
    "    print(f\"\\n{aspect}:\")\n",
    "    print(f\"  TinyRoBERTa mean: {tiny_data.mean():.3f} (std: {tiny_data.std():.3f})\")\n",
    "    print(f\"  DistilBERT mean: {distil_data.mean():.3f} (std: {distil_data.std():.3f})\")\n",
    "    print(f\"  t-statistic: {t_stat:.4f}\")\n",
    "    print(f\"  p-value: {p_value:.4f}\")\n",
    "    print(f\"  Significant? {'Yes (p < 0.05)' if p_value < 0.05 else 'No (p >= 0.05)'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b41374d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANOVA: Compare sentiment across aspects\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ANOVA: ASPECT COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "food_data = df_all[df_all['Aspect'] == 'Food']['Sentiment_Label']\n",
    "service_data = df_all[df_all['Aspect'] == 'Service']['Sentiment_Label']\n",
    "ambiance_data = df_all[df_all['Aspect'] == 'Ambiance']['Sentiment_Label']\n",
    "\n",
    "f_stat, p_value = stats.f_oneway(food_data, service_data, ambiance_data)\n",
    "\n",
    "print(f\"\\nFood mean: {food_data.mean():.3f} (std: {food_data.std():.3f})\")\n",
    "print(f\"Service mean: {service_data.mean():.3f} (std: {service_data.std():.3f})\")\n",
    "print(f\"Ambiance mean: {ambiance_data.mean():.3f} (std: {ambiance_data.std():.3f})\")\n",
    "print(f\"\\nF-statistic: {f_stat:.4f}\")\n",
    "print(f\"p-value: {p_value:.4f}\")\n",
    "print(f\"Significant? {'Yes (p < 0.05)' if p_value < 0.05 else 'No (p >= 0.05)'}\")\n",
    "\n",
    "if p_value < 0.05:\n",
    "    print(\"\\n✓ There are statistically significant differences in sentiment across aspects\")\n",
    "else:\n",
    "    print(\"\\n✗ No statistically significant differences in sentiment across aspects\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
