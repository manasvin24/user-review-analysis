{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e698359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# installs dependencies and imports required libraries.\n",
    "%pip install -q pandas torch nltk sentence-transformers transformers tqdm\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import torch\n",
    "from nltk.corpus import words\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from tqdm.auto import tqdm\n",
    "from transformers import pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c91629a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specifying the input data location.\n",
    "DATA_PATH = Path('../review_datasets/BDFoodSent-334k.csv')  # Adjust this path as needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a1aec8",
   "metadata": {},
   "source": [
    "aspect_questions maps taste, service, and ambiance queries so df_reviews can load from DATA_PATH and initialize qa_pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfb6597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing aspect questions and initializing the qa pipeline.\n",
    "aspect_questions = {\n",
    "    'Taste_Aspect': 'What is the opinion about the taste, quantity or food quality?',\n",
    "    'Service_Aspect': 'What is the feedback on the service or delivery?',\n",
    "    \"Ambiance_Aspect\": \"What is the description of the restaurant's atmosphere or environment?\"\n",
    "}\n",
    "\n",
    "df_reviews = pd.read_csv(DATA_PATH)\n",
    "qa_pipeline = pipeline('question-answering', model='deepset/bert-base-cased-squad2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f3eade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# running qa extraction for each review and aspect.\n",
    "results = []\n",
    "\n",
    "for _, row in tqdm(df_reviews.iterrows(), total=len(df_reviews), desc='QA extraction'):\n",
    "    review_text = row['text']\n",
    "    restaurant_id = row['name']\n",
    "    city = row['city']\n",
    "\n",
    "    for aspect, question_text in aspect_questions.items():\n",
    "        try:\n",
    "            output = qa_pipeline(question=question_text, context=review_text)\n",
    "            answer = output.get('answer', '')\n",
    "            score = output.get('score', 0.0)\n",
    "        except Exception:\n",
    "            answer = ''\n",
    "            score = 0.0\n",
    "\n",
    "        results.append({\n",
    "            'review': review_text,\n",
    "            'restaurant_id': restaurant_id,\n",
    "            'city': city,\n",
    "            'question': aspect,\n",
    "            'answer': answer,\n",
    "            'confidence': score\n",
    "        })\n",
    "\n",
    "df_results = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e48ded",
   "metadata": {},
   "source": [
    "df_results collects review, restaurant_id, city, question, answer, and confidence columns before previewing the first rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c6381e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# previewing the qa extraction results.\n",
    "df_results.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7831c92",
   "metadata": {},
   "source": [
    "df_results gains cosine_sim scores to quantify alignment between each question-answer pair.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1869db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing cosine similarity between questions and answers.\n",
    "tqdm.pandas()\n",
    "sentence_model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')\n",
    "\n",
    "def calculate_similarity(row):\n",
    "    \"\"\"Calculate cosine similarity between question and answer embeddings.\n",
    "    \n",
    "    Args:\n",
    "        row (pd.Series): A row from the DataFrame containing 'question' and 'answer' columns.\n",
    "\n",
    "    Returns:\n",
    "        float: Cosine similarity score between question and answer embeddings.\n",
    "    \"\"\"\n",
    "    question = row['question']\n",
    "    answer = row['answer']\n",
    "\n",
    "    if not isinstance(answer, str) or not answer.strip():\n",
    "        return 0.0\n",
    "\n",
    "    q_emb = sentence_model.encode(question, convert_to_tensor=True)\n",
    "    a_emb = sentence_model.encode(answer, convert_to_tensor=True)\n",
    "\n",
    "    if q_emb.dim() == 1:\n",
    "        q_emb = q_emb.unsqueeze(0)\n",
    "    if a_emb.dim() == 1:\n",
    "        a_emb = a_emb.unsqueeze(0)\n",
    "\n",
    "    return util.cos_sim(q_emb, a_emb).item()\n",
    "\n",
    "df_results['cosine_sim'] = df_results.progress_apply(calculate_similarity, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e1c4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloading vocabulary resources and defining filtering helpers.\n",
    "nltk.download('words')\n",
    "ENGLISH_WORDS = set(words.words())\n",
    "WORD_RE = re.compile(r'[A-Za-z]+')\n",
    "\n",
    "def filter_short_sentences(df, column, min_words=5):\n",
    "    \"\"\"Filter out sentences with fewer than a specified number of words.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the text data.\n",
    "        column (str): Name of the column containing text to filter.\n",
    "        min_words (int, optional): Minimum number of words required to keep a sentence. Defaults to 5.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered DataFrame with sentences meeting the word count criteria.\n",
    "    \"\"\"\n",
    "    mask = df[column].apply(lambda text: len(str(text).split()) >= min_words)\n",
    "    return df[mask].reset_index(drop=True)\n",
    "\n",
    "def filter_english_heavy(df, column, threshold=0.5):\n",
    "    \"\"\"Filter out sentences with a low ratio of English words.\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the text data.\n",
    "        column (str): Name of the column containing text to filter.\n",
    "        threshold (float, optional): Minimum ratio of English words required to keep a sentence. Defaults to 0.5.\n",
    "    Returns:\n",
    "        pd.DataFrame: Filtered DataFrame with sentences meeting the English word ratio criteria.\n",
    "    \"\"\"\n",
    "    def english_ratio(text):\n",
    "        \"\"\"Calculate the ratio of English words in the given text.\n",
    "        Args:\n",
    "            text (str): The text to analyze.\n",
    "        Returns:\n",
    "            float: Ratio of English words to total words in the text.\"\"\"\n",
    "        tokens = WORD_RE.findall(str(text).lower())\n",
    "        if not tokens:\n",
    "            return 0\n",
    "        eng_count = sum(1 for token in tokens if token in ENGLISH_WORDS)\n",
    "        return eng_count / len(tokens)\n",
    "\n",
    "    mask = df[column].apply(lambda text: english_ratio(text) >= threshold)\n",
    "    return df[mask].reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077cdf1c",
   "metadata": {},
   "source": [
    "filtered_df retains reviews where review length exceeds three words and english_ratio meets the 0.5 threshold.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4e7e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying text filters to refine the qa results.\n",
    "filtered_df = filter_short_sentences(df_results, 'review', min_words=3)\n",
    "filtered_df = filter_english_heavy(filtered_df, 'review', threshold=0.5)\n",
    "filtered_df.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bea9f46",
   "metadata": {},
   "source": [
    "filter_top_aspect sorts filtered_df by cosine_sim per aspect to extract df_food, df_ambiance, and df_service subsets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9b3b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting top reviews per aspect using cosine similarity.\n",
    "def filter_top_aspect(df, aspect_label):\n",
    "    \"\"\"Filter reviews by aspect and select the top 10% based on cosine similarity.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): DataFrame containing the review data.\n",
    "        aspect_label (str): The aspect label to filter by.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the full subset and the top 10% subset based on cosine similarity.\n",
    "    \"\"\"\n",
    "    subset = df[df['question'] == aspect_label].copy()\n",
    "    subset = subset.sort_values(by='cosine_sim', ascending=False)\n",
    "    top_n = int(len(subset) * 0.1)\n",
    "    top_subset = subset.head(top_n) if top_n > 0 else subset\n",
    "    return subset, top_subset\n",
    "\n",
    "food_full, df_food = filter_top_aspect(filtered_df, 'Taste_Aspect')\n",
    "ambiance_full, df_ambiance = filter_top_aspect(filtered_df, 'Ambiance_Aspect')\n",
    "service_full, df_service = filter_top_aspect(filtered_df, 'Service_Aspect')\n",
    "\n",
    "print(f\"Food (Taste): Full Shape {food_full.shape}, Top 10% Shape {df_food.shape}\")\n",
    "print(f\"Ambiance: Full Shape {ambiance_full.shape}, Top 10% Shape {df_ambiance.shape}\")\n",
    "print(f\"Service: Full Shape {service_full.shape}, Top 10% Shape {df_service.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb136f1",
   "metadata": {},
   "source": [
    "df_food, df_ambiance, and df_service each receive sentiment scores from sentiment_pipe and expand with a sentiment column.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9da23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing sentiment scoring on the aspect-specific reviews.\n",
    "sentiment_pipe = pipeline(\n",
    "    'sentiment-analysis',\n",
    "    model='nlptown/bert-base-multilingual-uncased-sentiment',\n",
    "    device=0 if torch.cuda.is_available() else -1\n",
    ")\n",
    "\n",
    "def get_sentiment_score(review):\n",
    "    \"\"\"Get sentiment score for a given review text.\n",
    "    Args:\n",
    "        review (str): The review text to analyze.\n",
    "    Returns:\n",
    "        float: Sentiment score of the review.\n",
    "    \"\"\"\n",
    "    if not isinstance(review, str):\n",
    "        review = str(review)\n",
    "    return sentiment_pipe(review)[0]['score']\n",
    "\n",
    "print('Processing Food Reviews...')\n",
    "df_food['sentiment'] = df_food['review'].progress_apply(get_sentiment_score)\n",
    "\n",
    "print('Processing Ambiance Reviews...')\n",
    "df_ambiance['sentiment'] = df_ambiance['review'].progress_apply(get_sentiment_score)\n",
    "\n",
    "print('Processing Service Reviews...')\n",
    "df_service['sentiment'] = df_service['review'].progress_apply(get_sentiment_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c2f7770",
   "metadata": {},
   "source": [
    "food_output, ambiance_output, and service_output paths capture the final CSV shapes for downstream notebooks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb120545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write sentiment outputs to the results directory.\n",
    "results_dir = Path('../results')\n",
    "results_dir.mkdir(exist_ok=True)\n",
    "\n",
    "food_output = results_dir / 'food_sentiment_bert_base_cased.csv'\n",
    "ambiance_output = results_dir / 'ambiance_sentiment_bert_base_cased.csv'\n",
    "service_output = results_dir / 'service_sentiment_bert_base_cased.csv'\n",
    "\n",
    "df_food.to_csv(food_output, index=False)\n",
    "df_ambiance.to_csv(ambiance_output, index=False)\n",
    "df_service.to_csv(service_output, index=False)\n",
    "\n",
    "print(f'Saved {food_output.name}, {ambiance_output.name}, {service_output.name} to {results_dir}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8467710a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing no operation in this cell.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
